{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMexEJAcQmiSPH07qIp3UB5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VRSFXECE/VRS/blob/main/swtransret.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "ujJu_OmZaQxm",
        "outputId": "408638c3-9df8-46c1-f0de-ddd3ee5257a9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4131036090.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSwinForImageClassification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSwinImageProcessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoImageProcessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForImageClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2315\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2317\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2318\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2345\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2346\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2347\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2349\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2344\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2345\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2346\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2347\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/swin/modeling_swin.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mactivations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mACT2FN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mmodeling_layers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGradientCheckpointingLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mmodeling_outputs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBackboneOutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mmodeling_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPreTrainedModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mTokenClassifierOutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m )\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mprocessing_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUnpack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTransformersKwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto_docstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcan_return_tuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2315\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2317\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2318\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2345\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2346\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2347\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2349\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2344\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2345\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2346\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2347\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/modeling_auto.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m from .auto_factory import (\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0m_BaseAutoBackboneClass\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0m_BaseAutoModelClass\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mgeneration\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenerationMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2315\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2317\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2318\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2345\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2346\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2347\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2349\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2344\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2345\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2346\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2347\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m )\n\u001b[0;32m---> 55\u001b[0;31m from .candidate_generator import (\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mAssistantVocabTranslatorCache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mAssistedCandidateGenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/candidate_generator.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_sklearn_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0misin_mps_friendly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0m_distributor_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m )\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclone\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInconsistentVersionWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_HTMLDocumentationLinkMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata_requests\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_MetadataRequester\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_routing_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvalidate_parameter_constraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_joblib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata_routing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_bunch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBunch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_chunking\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgen_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_chunking.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInterval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_is_arraylike_not_scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_get_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataConversionWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPositiveSpectrumWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_array_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_is_numpy_namespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_deprecate_force_all_finite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_preserve_dia_indices_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparse_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0m_NUMPY_NAMESPACE_NAMES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"numpy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"array_api_compat.numpy\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mpd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# numpy compat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m from pandas.compat import (\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mnp_version_under1p18\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_np_version_under1p18\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mis_numpy_dev\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_is_numpy_dev\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/compat/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m from pandas.compat.numpy import (\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mis_numpy_dev\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mnp_array_datetime64_compat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/compat/numpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVersion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# numpy versioning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/util/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from pandas.util._decorators import (  # noqa\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mAppender\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mSubstitution\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcache_readonly\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproperties\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcache_readonly\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/_libs/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterval\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInterval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m from pandas._libs.tslibs import (\n\u001b[1;32m     15\u001b[0m     \u001b[0mNaT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/_libs/interval.pyx\u001b[0m in \u001b[0;36minit pandas._libs.interval\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
          ]
        }
      ],
      "source": [
        "#!pip install SwinImageProcessor\n",
        "#!pip install AutoImageProcessor\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import SwinForImageClassification, SwinImageProcessor\n",
        "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
        "from typing import List, Optional, Dict, Tuple, Union\n",
        "import warnings\n",
        "from collections import OrderedDict\n",
        "\n",
        "class SystemicDiseaseSwinTransformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Swin Transformer for Systemic Disease Detection from Retinal Fundus Images\n",
        "\n",
        "    Advantages over ViT for medical imaging:\n",
        "    - Hierarchical feature extraction\n",
        "    - Shifted window attention\n",
        "    - Better at capturing local and global features\n",
        "    - Often outperforms ViT on medical image tasks\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 diseases: List[str],\n",
        "                 model_name: str = \"microsoft/swin-tiny-patch4-window7-224\",\n",
        "                 pretrained_path: Optional[str] = None,\n",
        "                 dropout_rate: float = 0.4,\n",
        "                 use_multi_label: bool = True,\n",
        "                 use_auxiliary_classifier: bool = False):\n",
        "        \"\"\"\n",
        "        Initialize Swin Transformer for disease detection\n",
        "\n",
        "        Args:\n",
        "            diseases: List of systemic diseases to detect\n",
        "            model_name: Pretrained Swin model name\n",
        "            pretrained_path: Path to custom pretrained weights\n",
        "            dropout_rate: Dropout probability\n",
        "            use_multi_label: Multi-label classification (True) or multi-class (False)\n",
        "            use_auxiliary_classifier: Use auxiliary classifiers from intermediate stages\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.diseases = diseases\n",
        "        self.num_diseases = len(diseases)\n",
        "        self.model_name = model_name\n",
        "        self.use_multi_label = use_multi_label\n",
        "        self.use_auxiliary_classifier = use_auxiliary_classifier\n",
        "\n",
        "        print(f\"Initializing Swin Transformer for {self.num_diseases} systemic diseases:\")\n",
        "        for i, disease in enumerate(diseases):\n",
        "            print(f\"  {i}: {disease}\")\n",
        "\n",
        "        # Load pre-trained Swin Transformer\n",
        "        try:\n",
        "            self.swin_model = SwinForImageClassification.from_pretrained(\n",
        "                model_name,\n",
        "                num_labels=self.num_diseases,\n",
        "                ignore_mismatched_sizes=True\n",
        "            )\n",
        "            print(f\"✓ Loaded pretrained Swin model: {model_name}\")\n",
        "        except Exception as e:\n",
        "            warnings.warn(f\"Could not load pretrained model: {e}\")\n",
        "            from transformers import SwinConfig\n",
        "            config = SwinConfig.from_pretrained(model_name)\n",
        "            config.num_labels = self.num_diseases\n",
        "            self.swin_model = SwinForImageClassification(config)\n",
        "            print(f\"✓ Initialized new Swin model with config: {model_name}\")\n",
        "\n",
        "        # Get model configuration\n",
        "        self.config = self.swin_model.config\n",
        "        hidden_size = self.config.hidden_size\n",
        "\n",
        "        # Store original classifier for reference\n",
        "        self.original_classifier = self.swin_model.classifier\n",
        "\n",
        "        # Replace classification head with custom head\n",
        "        print(f\"Original hidden size: {hidden_size}\")\n",
        "\n",
        "        # Enhanced classification head for medical imaging\n",
        "        self.classifier = self._build_enhanced_classifier(\n",
        "            hidden_size=hidden_size,\n",
        "            dropout_rate=dropout_rate\n",
        "        )\n",
        "\n",
        "        # Replace model's classifier\n",
        "        self.swin_model.classifier = nn.Identity()  # Remove original\n",
        "\n",
        "        # Optional: Auxiliary classifiers from different stages\n",
        "        if use_auxiliary_classifier:\n",
        "            self.auxiliary_classifiers = self._build_auxiliary_classifiers()\n",
        "        else:\n",
        "            self.auxiliary_classifiers = None\n",
        "\n",
        "        # Load custom pretrained weights if provided\n",
        "        if pretrained_path is not None:\n",
        "            self.load_custom_weights(pretrained_path)\n",
        "\n",
        "        # Initialize image processor for fundus images\n",
        "        self.processor = self._initialize_image_processor()\n",
        "\n",
        "        # Setup disease mapping\n",
        "        self._setup_disease_mapping()\n",
        "\n",
        "        # Initialize loss function\n",
        "        self._initialize_loss_function()\n",
        "\n",
        "        # Count parameters\n",
        "        self._count_parameters()\n",
        "\n",
        "    def _build_enhanced_classifier(self, hidden_size: int, dropout_rate: float) -> nn.Module:\n",
        "        \"\"\"Build enhanced classifier for disease detection\"\"\"\n",
        "        print(f\"Building enhanced classifier with dropout={dropout_rate}\")\n",
        "\n",
        "        # Multi-layer classifier with batch normalization\n",
        "        classifier_layers = [\n",
        "            nn.LayerNorm(hidden_size),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(hidden_size, hidden_size // 2),\n",
        "            nn.GELU(),\n",
        "            nn.BatchNorm1d(hidden_size // 2),\n",
        "            nn.Dropout(dropout_rate / 2),\n",
        "            nn.Linear(hidden_size // 2, self.num_diseases)\n",
        "        ]\n",
        "\n",
        "        # Add attention pooling if needed\n",
        "        if self.num_diseases > 10:  # For many diseases, add more capacity\n",
        "            classifier_layers.insert(2, nn.Linear(hidden_size // 2, hidden_size // 4))\n",
        "            classifier_layers.insert(3, nn.GELU())\n",
        "            classifier_layers.insert(4, nn.Dropout(dropout_rate / 3))\n",
        "            classifier_layers.insert(5, nn.Linear(hidden_size // 4, hidden_size // 2))\n",
        "            classifier_layers.insert(6, nn.GELU())\n",
        "\n",
        "        classifier = nn.Sequential(*classifier_layers)\n",
        "\n",
        "        # Initialize weights\n",
        "        self._initialize_classifier_weights(classifier)\n",
        "\n",
        "        return classifier\n",
        "\n",
        "    def _build_auxiliary_classifiers(self) -> nn.ModuleDict:\n",
        "        \"\"\"Build auxiliary classifiers from intermediate stages\"\"\"\n",
        "        print(\"Building auxiliary classifiers for multi-stage features\")\n",
        "\n",
        "        # Swin has 4 stages with different feature dimensions\n",
        "        stage_dims = [\n",
        "            self.config.hidden_size,  # Stage 1\n",
        "            self.config.hidden_size * 2,  # Stage 2\n",
        "            self.config.hidden_size * 4,  # Stage 3\n",
        "            self.config.hidden_size * 8,  # Stage 4\n",
        "        ]\n",
        "\n",
        "        auxiliary_classifiers = nn.ModuleDict()\n",
        "\n",
        "        for i, dim in enumerate(stage_dims[:-1]):  # Exclude last stage (main classifier)\n",
        "            aux_classifier = nn.Sequential(\n",
        "                nn.AdaptiveAvgPool2d(1),\n",
        "                nn.Flatten(),\n",
        "                nn.LayerNorm(dim),\n",
        "                nn.Linear(dim, dim // 4),\n",
        "                nn.GELU(),\n",
        "                nn.Dropout(0.3),\n",
        "                nn.Linear(dim // 4, self.num_diseases)\n",
        "            )\n",
        "            auxiliary_classifiers[f'stage_{i+1}'] = aux_classifier\n",
        "\n",
        "        return auxiliary_classifiers\n",
        "\n",
        "    def _initialize_classifier_weights(self, classifier: nn.Module):\n",
        "        \"\"\"Initialize classifier weights properly\"\"\"\n",
        "        for module in classifier.modules():\n",
        "            if isinstance(module, nn.Linear):\n",
        "                nn.init.xavier_uniform_(module.weight)\n",
        "                if module.bias is not None:\n",
        "                    nn.init.zeros_(module.bias)\n",
        "            elif isinstance(module, nn.LayerNorm):\n",
        "                nn.init.ones_(module.weight)\n",
        "                nn.init.zeros_(module.bias)\n",
        "\n",
        "    def _initialize_image_processor(self):\n",
        "        \"\"\"Initialize image processor for retinal fundus images\"\"\"\n",
        "        try:\n",
        "            processor = SwinImageProcessor.from_pretrained(self.model_name)\n",
        "            print(f\"✓ Loaded SwinImageProcessor for {self.model_name}\")\n",
        "        except:\n",
        "            try:\n",
        "                processor = AutoImageProcessor.from_pretrained(self.model_name)\n",
        "                print(f\"✓ Loaded AutoImageProcessor for {self.model_name}\")\n",
        "            except:\n",
        "                processor = SwinImageProcessor(\n",
        "                    size={\"height\": 224, \"width\": 224},\n",
        "                    do_resize=True,\n",
        "                    do_rescale=True,\n",
        "                    do_normalize=True,\n",
        "                    image_mean=[0.485, 0.456, 0.406],\n",
        "                    image_std=[0.229, 0.224, 0.225],\n",
        "                )\n",
        "                print(\"✓ Created default SwinImageProcessor\")\n",
        "\n",
        "        # Medical imaging adjustments\n",
        "        processor.do_rescale = True\n",
        "        processor.rescale_factor = 1.0 / 255.0\n",
        "\n",
        "        return processor\n",
        "\n",
        "    def _setup_disease_mapping(self):\n",
        "        \"\"\"Setup disease ID mappings\"\"\"\n",
        "        self.disease_to_id = {disease: i for i, disease in enumerate(self.diseases)}\n",
        "        self.id_to_disease = {i: disease for i, disease in enumerate(self.diseases)}\n",
        "\n",
        "        # Update model config\n",
        "        self.swin_model.config.id2label = self.id_to_disease\n",
        "        self.swin_model.config.label2id = self.disease_to_id\n",
        "\n",
        "    def _initialize_loss_function(self):\n",
        "        \"\"\"Initialize appropriate loss function\"\"\"\n",
        "        if self.use_multi_label:\n",
        "            self.criterion = nn.BCEWithLogitsLoss()\n",
        "            print(\"Loss: BCEWithLogitsLoss (multi-label)\")\n",
        "        else:\n",
        "            self.criterion = nn.CrossEntropyLoss()\n",
        "            print(\"Loss: CrossEntropyLoss (multi-class)\")\n",
        "\n",
        "    def _count_parameters(self):\n",
        "        \"\"\"Count and display model parameters\"\"\"\n",
        "        total_params = sum(p.numel() for p in self.parameters())\n",
        "        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "        print(f\"\\nParameter Count:\")\n",
        "        print(f\"  Total parameters: {total_params:,}\")\n",
        "        print(f\"  Trainable parameters: {trainable_params:,}\")\n",
        "        print(f\"  Trainable %: {100 * trainable_params / total_params:.2f}%\")\n",
        "\n",
        "    def forward(self, pixel_values: torch.Tensor) -> Union[torch.Tensor, Dict[str, torch.Tensor]]:\n",
        "        \"\"\"\n",
        "        Forward pass through Swin Transformer\n",
        "\n",
        "        Returns:\n",
        "            - If not using auxiliary: logits tensor\n",
        "            - If using auxiliary: dict with main and auxiliary logits\n",
        "        \"\"\"\n",
        "        # Get features from Swin backbone\n",
        "        outputs = self.swin_model.swin(\n",
        "            pixel_values=pixel_values,\n",
        "            output_hidden_states=self.use_auxiliary_classifier,\n",
        "            output_attentions=False,\n",
        "            return_dict=True\n",
        "        )\n",
        "\n",
        "        # Get pooled output (usually from last hidden state)\n",
        "        pooled_output = outputs.pooler_output\n",
        "\n",
        "        # Main classifier\n",
        "        main_logits = self.classifier(pooled_output)\n",
        "\n",
        "        if not self.use_auxiliary_classifier:\n",
        "            return main_logits\n",
        "\n",
        "        # Get auxiliary outputs if enabled\n",
        "        hidden_states = outputs.hidden_states\n",
        "\n",
        "        auxiliary_outputs = {}\n",
        "        for i, (stage_name, aux_classifier) in enumerate(self.auxiliary_classifiers.items()):\n",
        "            # Get hidden state for this stage (skip first which is embeddings)\n",
        "            stage_features = hidden_states[i + 1]\n",
        "\n",
        "            # For Swin, we need to reshape from (B, L, C) to (B, C, H, W) for pooling\n",
        "            batch_size, seq_len, channels = stage_features.shape\n",
        "            # Assuming square features: sqrt(seq_len) should be integer\n",
        "            h = w = int(seq_len ** 0.5)\n",
        "            stage_features = stage_features.transpose(1, 2).reshape(batch_size, channels, h, w)\n",
        "\n",
        "            aux_logits = aux_classifier(stage_features)\n",
        "            auxiliary_outputs[stage_name] = aux_logits\n",
        "\n",
        "        return {\n",
        "            'main': main_logits,\n",
        "            'auxiliary': auxiliary_outputs\n",
        "        }\n",
        "\n",
        "    def predict_proba(self, pixel_values: torch.Tensor,\n",
        "                     temperature: float = 1.0) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Get probability predictions with optional temperature scaling\n",
        "\n",
        "        Args:\n",
        "            pixel_values: Input images\n",
        "            temperature: Temperature for softmax (for calibration)\n",
        "\n",
        "        Returns:\n",
        "            Probability tensor\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            output = self.forward(pixel_values)\n",
        "\n",
        "            if isinstance(output, dict):\n",
        "                logits = output['main']\n",
        "            else:\n",
        "                logits = output\n",
        "\n",
        "            if self.use_multi_label:\n",
        "                # Multi-label: independent sigmoid\n",
        "                probs = torch.sigmoid(logits / temperature)\n",
        "            else:\n",
        "                # Multi-class: softmax\n",
        "                probs = F.softmax(logits / temperature, dim=-1)\n",
        "\n",
        "            return probs\n",
        "\n",
        "    def preprocess_fundus_image(self, image: Union[torch.Tensor, 'Image.Image', np.ndarray],\n",
        "                               apply_clahe: bool = False) -> Dict[str, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Preprocess retinal fundus image for Swin Transformer\n",
        "\n",
        "        Args:\n",
        "            image: Input image (PIL, Tensor, or numpy array)\n",
        "            apply_clahe: Apply CLAHE enhancement (for low contrast fundus images)\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with processed pixel values\n",
        "        \"\"\"\n",
        "        from PIL import Image\n",
        "        import numpy as np\n",
        "\n",
        "        # Convert to PIL Image if needed\n",
        "        if isinstance(image, torch.Tensor):\n",
        "            if image.dim() == 3:\n",
        "                image = image.permute(1, 2, 0) if image.shape[0] in [1, 3] else image\n",
        "            image = Image.fromarray((image.cpu().numpy() * 255).astype(np.uint8))\n",
        "        elif isinstance(image, np.ndarray):\n",
        "            if image.max() <= 1.0:\n",
        "                image = (image * 255).astype(np.uint8)\n",
        "            image = Image.fromarray(image)\n",
        "\n",
        "        # Optional: Apply CLAHE for contrast enhancement\n",
        "        if apply_clahe:\n",
        "            try:\n",
        "                image = self._apply_clahe(image)\n",
        "            except:\n",
        "                warnings.warn(\"CLAHE failed, using original image\")\n",
        "\n",
        "        # Apply Swin Transformer preprocessing\n",
        "        inputs = self.processor(images=image, return_tensors=\"pt\")\n",
        "\n",
        "        # Additional medical-specific normalization\n",
        "        if hasattr(self, 'normalize_fundus'):\n",
        "            inputs['pixel_values'] = self.normalize_fundus(inputs['pixel_values'])\n",
        "\n",
        "        return inputs\n",
        "\n",
        "    def _apply_clahe(self, image: 'Image.Image') -> 'Image.Image':\n",
        "        \"\"\"Apply CLAHE contrast enhancement\"\"\"\n",
        "        import cv2\n",
        "        import numpy as np\n",
        "\n",
        "        # Convert PIL to numpy\n",
        "        img_array = np.array(image)\n",
        "\n",
        "        # Convert to LAB color space\n",
        "        if len(img_array.shape) == 3 and img_array.shape[2] == 3:\n",
        "            lab = cv2.cvtColor(img_array, cv2.COLOR_RGB2LAB)\n",
        "            l, a, b = cv2.split(lab)\n",
        "\n",
        "            # Apply CLAHE to L channel\n",
        "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "            cl = clahe.apply(l)\n",
        "\n",
        "            # Merge channels\n",
        "            limg = cv2.merge((cl, a, b))\n",
        "\n",
        "            # Convert back to RGB\n",
        "            enhanced = cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)\n",
        "        else:\n",
        "            # Grayscale image\n",
        "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "            enhanced = clahe.apply(img_array)\n",
        "\n",
        "        return Image.fromarray(enhanced)\n",
        "\n",
        "    def freeze_backbone_layers(self, unfreeze_last_n: int = 2):\n",
        "        \"\"\"\n",
        "        Freeze Swin Transformer backbone layers\n",
        "\n",
        "        Args:\n",
        "            unfreeze_last_n: Number of Swin stages to unfreeze (1-4)\n",
        "                            1: Only last stage trainable\n",
        "                            4: All stages trainable\n",
        "        \"\"\"\n",
        "        unfreeze_last_n = max(1, min(4, unfreeze_last_n))\n",
        "\n",
        "        # Freeze entire model first\n",
        "        for param in self.swin_model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Unfreeze specified number of stages\n",
        "        stages_to_unfreeze = list(range(4 - unfreeze_last_n, 4))\n",
        "\n",
        "        for stage_idx in stages_to_unfreeze:\n",
        "            # Unfreeze attention layers in this stage\n",
        "            stage_layers = self.swin_model.swin.encoder.layers[stage_idx].blocks\n",
        "            for block in stage_layers:\n",
        "                for param in block.parameters():\n",
        "                    param.requires_grad = True\n",
        "\n",
        "            # Unfreeze patch merging if not last stage\n",
        "            if stage_idx < 3:  # Swin has 3 patch merging layers\n",
        "                patch_merge = self.swin_model.swin.encoder.layers[stage_idx].downsample\n",
        "                if patch_merge is not None:\n",
        "                    for param in patch_merge.parameters():\n",
        "                        param.requires_grad = True\n",
        "\n",
        "        # Always unfreeze classifier\n",
        "        for param in self.classifier.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "        if self.auxiliary_classifiers is not None:\n",
        "            for param in self.auxiliary_classifiers.parameters():\n",
        "                param.requires_grad = True\n",
        "\n",
        "        print(f\"Unfroze last {unfreeze_last_n} Swin stages (stages {stages_to_unfreeze})\")\n",
        "        print(\"Classifier and auxiliary heads are trainable\")\n",
        "\n",
        "    def get_attention_maps(self, pixel_values: torch.Tensor,\n",
        "                          stage_idx: int = -1,\n",
        "                          head_idx: Optional[int] = None) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Extract attention maps from Swin Transformer\n",
        "\n",
        "        Args:\n",
        "            pixel_values: Input images\n",
        "            stage_idx: Stage index (0-3, -1 for last)\n",
        "            head_idx: Specific attention head (None for average)\n",
        "\n",
        "        Returns:\n",
        "            Attention maps\n",
        "        \"\"\"\n",
        "        self.eval()\n",
        "\n",
        "        if stage_idx == -1:\n",
        "            stage_idx = len(self.swin_model.swin.encoder.layers) - 1\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Get attention outputs\n",
        "            outputs = self.swin_model.swin(\n",
        "                pixel_values=pixel_values,\n",
        "                output_attentions=True,\n",
        "                return_dict=True\n",
        "            )\n",
        "\n",
        "            # Get attention from specified stage\n",
        "            attentions = outputs.attentions[stage_idx]  # [batch, num_heads, window_num, window_size, window_size]\n",
        "\n",
        "            if head_idx is not None:\n",
        "                # Specific head\n",
        "                attention_maps = attentions[:, head_idx]\n",
        "            else:\n",
        "                # Average across heads\n",
        "                attention_maps = attentions.mean(dim=1)\n",
        "\n",
        "            return attention_maps\n",
        "\n",
        "    def load_custom_weights(self, path: str, strict: bool = False):\n",
        "        \"\"\"Load custom pretrained weights\"\"\"\n",
        "        try:\n",
        "            checkpoint = torch.load(path, map_location='cpu')\n",
        "\n",
        "            if 'model_state_dict' in checkpoint:\n",
        "                state_dict = checkpoint['model_state_dict']\n",
        "            elif 'state_dict' in checkpoint:\n",
        "                state_dict = checkpoint['state_dict']\n",
        "            else:\n",
        "                state_dict = checkpoint\n",
        "\n",
        "            # Filter out incompatible classifier weights\n",
        "            model_state_dict = self.state_dict()\n",
        "            filtered_dict = {}\n",
        "\n",
        "            for k, v in state_dict.items():\n",
        "                # Handle classifier key differences\n",
        "                if 'classifier' in k and 'swin_model.classifier' not in k:\n",
        "                    # Adjust key names if needed\n",
        "                    new_key = k.replace('classifier', 'swin_model.classifier')\n",
        "                    if new_key in model_state_dict:\n",
        "                        filtered_dict[new_key] = v\n",
        "                elif k in model_state_dict and model_state_dict[k].shape == v.shape:\n",
        "                    filtered_dict[k] = v\n",
        "\n",
        "            # Load filtered weights\n",
        "            self.load_state_dict(filtered_dict, strict=strict)\n",
        "\n",
        "            print(f\"✓ Loaded custom weights from {path}\")\n",
        "            print(f\"  Loaded {len(filtered_dict)}/{len(state_dict)} parameters\")\n",
        "\n",
        "        except Exception as e:\n",
        "            warnings.warn(f\"Failed to load custom weights: {e}\")\n",
        "\n",
        "    def get_feature_maps(self, pixel_values: torch.Tensor,\n",
        "                        stage_idx: int = -1) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Extract feature maps from specific Swin stage\n",
        "\n",
        "        Useful for visualization and interpretability\n",
        "        \"\"\"\n",
        "        self.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = self.swin_model.swin(\n",
        "                pixel_values=pixel_values,\n",
        "                output_hidden_states=True,\n",
        "                return_dict=True\n",
        "            )\n",
        "\n",
        "            hidden_states = outputs.hidden_states\n",
        "\n",
        "            if stage_idx == -1:\n",
        "                # Last hidden state\n",
        "                features = hidden_states[-1]\n",
        "            else:\n",
        "                features = hidden_states[stage_idx]\n",
        "\n",
        "            return features\n",
        "\n",
        "    def summary(self):\n",
        "        \"\"\"Print model summary\"\"\"\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"SYSTEMIC DISEASE SWIN TRANSFORMER SUMMARY\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"Model: {self.model_name}\")\n",
        "        print(f\"Diseases: {self.num_diseases}\")\n",
        "        print(f\"Multi-label: {self.use_multi_label}\")\n",
        "        print(f\"Auxiliary classifiers: {self.use_auxiliary_classifier}\")\n",
        "\n",
        "        # Print layer information\n",
        "        print(\"\\nSwin Transformer Architecture:\")\n",
        "        print(f\"  Hidden size: {self.config.hidden_size}\")\n",
        "        print(f\"  Layers: {self.config.num_hidden_layers}\")\n",
        "        print(f\"  Heads: {self.config.num_attention_heads}\")\n",
        "        print(f\"  Window size: {self.config.window_size}\")\n",
        "        print(f\"  MLP ratio: {self.config.mlp_ratio}\")\n",
        "\n",
        "        # Print classifier info\n",
        "        print(f\"\\nClassifier Architecture:\")\n",
        "        print(f\"  Input dim: {self.config.hidden_size}\")\n",
        "        print(f\"  Output dim: {self.num_diseases}\")\n",
        "        print(f\"  Dropout: {self.classifier[1].p if len(self.classifier) > 1 else 'N/A'}\")\n",
        "\n",
        "        # Count parameters\n",
        "        total_params = sum(p.numel() for p in self.parameters())\n",
        "        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "        print(f\"\\nParameters:\")\n",
        "        print(f\"  Total: {total_params:,}\")\n",
        "        print(f\"  Trainable: {trainable_params:,}\")\n",
        "        print(f\"  Percentage trainable: {100*trainable_params/total_params:.2f}%\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "\n",
        "def create_swin_disease_detector(\n",
        "    diseases: List[str],\n",
        "    model_variant: str = \"tiny\",\n",
        "    use_pretrained: bool = True,\n",
        "    device: Optional[str] = None,\n",
        "    **kwargs\n",
        ") -> SystemicDiseaseSwinTransformer:\n",
        "    \"\"\"\n",
        "    Factory function to create Swin Transformer disease detector\n",
        "\n",
        "    Args:\n",
        "        diseases: List of systemic diseases\n",
        "        model_variant: 'tiny', 'small', 'base', or 'large'\n",
        "        use_pretrained: Use pretrained weights\n",
        "        device: Target device\n",
        "        **kwargs: Additional arguments for SystemicDiseaseSwinTransformer\n",
        "\n",
        "    Returns:\n",
        "        Initialized Swin Transformer model\n",
        "    \"\"\"\n",
        "    # Map model variants to HuggingFace model names\n",
        "    model_map = {\n",
        "        'tiny': 'microsoft/swin-tiny-patch4-window7-224',\n",
        "        'small': 'microsoft/swin-small-patch4-window7-224',\n",
        "        'base': 'microsoft/swin-base-patch4-window7-224',\n",
        "        'large': 'microsoft/swin-large-patch4-window7-224',\n",
        "        'v2_tiny': 'microsoft/swinv2-tiny-patch4-window8-256',\n",
        "        'v2_base': 'microsoft/swinv2-base-patch4-window12to24-192to384-22kto1k',\n",
        "    }\n",
        "\n",
        "    if model_variant not in model_map:\n",
        "        print(f\"Warning: Model variant '{model_variant}' not found, using 'tiny'\")\n",
        "        model_variant = 'tiny'\n",
        "\n",
        "    model_name = model_map[model_variant]\n",
        "\n",
        "    if device is None:\n",
        "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    print(f\"🚀 Creating Swin Transformer ({model_variant}) for Systemic Disease Detection\")\n",
        "    print(f\"📊 Device: {device}\")\n",
        "    print(f\"🎯 Diseases: {', '.join(diseases)}\")\n",
        "\n",
        "    if use_pretrained:\n",
        "        model = SystemicDiseaseSwinTransformer(\n",
        "            diseases=diseases,\n",
        "            model_name=model_name,\n",
        "            **kwargs\n",
        "        )\n",
        "    else:\n",
        "        # Initialize from scratch (not recommended)\n",
        "        from transformers import SwinConfig\n",
        "        config = SwinConfig.from_pretrained(model_name)\n",
        "        config.num_labels = len(diseases)\n",
        "\n",
        "        swin_model = SwinForImageClassification(config)\n",
        "\n",
        "        model = SystemicDiseaseSwinTransformer(diseases=diseases, **kwargs)\n",
        "        model.swin_model = swin_model\n",
        "        model.swin_model.classifier = nn.Identity()\n",
        "\n",
        "    # Move to device\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Print summary\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Training utilities for Swin Transformer\n",
        "class SwinDiseaseTrainer:\n",
        "    \"\"\"Training utilities for Swin Transformer disease detection\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def train_epoch(model, dataloader, optimizer, device,\n",
        "                   scheduler=None, grad_clip: float = 1.0,\n",
        "                   aux_weight: float = 0.3):\n",
        "        \"\"\"Train for one epoch\"\"\"\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for batch_idx, (images, labels) in enumerate(dataloader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "\n",
        "            # Calculate loss\n",
        "            if isinstance(outputs, dict):\n",
        "                # With auxiliary classifiers\n",
        "                main_loss = SwinDiseaseTrainer._calculate_loss(\n",
        "                    outputs['main'], labels, model.criterion, model.use_multi_label\n",
        "                )\n",
        "\n",
        "                aux_loss = 0\n",
        "                if 'auxiliary' in outputs:\n",
        "                    for aux_logits in outputs['auxiliary'].values():\n",
        "                        aux_loss += SwinDiseaseTrainer._calculate_loss(\n",
        "                            aux_logits, labels, model.criterion, model.use_multi_label\n",
        "                        )\n",
        "                    aux_loss = aux_loss / len(outputs['auxiliary'])\n",
        "\n",
        "                loss = main_loss + aux_weight * aux_loss\n",
        "            else:\n",
        "                # Without auxiliary\n",
        "                loss = SwinDiseaseTrainer._calculate_loss(\n",
        "                    outputs, labels, model.criterion, model.use_multi_label\n",
        "                )\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping\n",
        "            if grad_clip > 0:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            if scheduler is not None:\n",
        "                scheduler.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Progress update\n",
        "            if (batch_idx + 1) % 10 == 0:\n",
        "                print(f\"  Batch {batch_idx+1}/{len(dataloader)}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "        return total_loss / len(dataloader)\n",
        "\n",
        "    @staticmethod\n",
        "    def _calculate_loss(logits, labels, criterion, is_multi_label):\n",
        "        \"\"\"Calculate loss based on task type\"\"\"\n",
        "        if is_multi_label:\n",
        "            return criterion(logits, labels.float())\n",
        "        else:\n",
        "            return criterion(logits, labels)\n",
        "\n",
        "    @staticmethod\n",
        "    def evaluate(model, dataloader, device,\n",
        "                threshold: float = 0.5):\n",
        "        \"\"\"Evaluate model performance\"\"\"\n",
        "        model.eval()\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        all_probs = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in dataloader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                # Get predictions\n",
        "                probs = model.predict_proba(images)\n",
        "\n",
        "                if model.use_multi_label:\n",
        "                    preds = (probs > threshold).float()\n",
        "                else:\n",
        "                    preds = torch.argmax(probs, dim=-1)\n",
        "\n",
        "                all_preds.append(preds.cpu())\n",
        "                all_labels.append(labels.cpu())\n",
        "                all_probs.append(probs.cpu())\n",
        "\n",
        "        preds_tensor = torch.cat(all_preds, dim=0)\n",
        "        labels_tensor = torch.cat(all_labels, dim=0)\n",
        "        probs_tensor = torch.cat(all_probs, dim=0)\n",
        "\n",
        "        return {\n",
        "            'predictions': preds_tensor,\n",
        "            'labels': labels_tensor,\n",
        "            'probabilities': probs_tensor\n",
        "        }\n",
        "\n",
        "\n",
        "# Example usage with medical dataset\n",
        "if __name__ == \"__main__\":\n",
        "    # Define systemic diseases detectable from retinal fundus images\n",
        "    systemic_diseases = [\n",
        "        \"Diabetes_Mellitus\",        # Diabetic retinopathy\n",
        "        \"Hypertension\",             # Hypertensive retinopathy\n",
        "        \"Anemia\",                   # Retinal pallor, hemorrhages\n",
        "        \"Atherosclerosis\",          # AV nicking, vascular changes\n",
        "        \"Sickle_Cell_Disease\",      # Sea fan neovascularization\n",
        "        \"HIV_Retinopathy\",          # Cotton wool spots, hemorrhages\n",
        "        \"Multiple_Sclerosis\",       # Optic neuritis\n",
        "        \"Leukemia\",                 # Roth spots, retinal infiltrates\n",
        "        \"Sarcoidosis\",              # Candle wax drippings\n",
        "        \"Systemic_Lupus\",           # Retinal vasculitis\n",
        "        \"Carotid_Artery_Disease\",   # Ocular ischemic syndrome\n",
        "        \"Hyperthyroidism\",          # Thyroid eye disease signs\n",
        "        \"Renal_Disease\",            # Hypertensive changes\n",
        "        \"Blood_Disorders\",          # Various hemorrhagic signs\n",
        "    ]\n",
        "\n",
        "    # Create Swin Transformer model\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"CREATING SWIN TRANSFORMER FOR SYSTEMIC DISEASE DETECTION\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    model = create_swin_disease_detector(\n",
        "        diseases=systemic_diseases,\n",
        "        model_variant=\"base\",  # Options: tiny, small, base, large, v2_tiny, v2_base\n",
        "        use_pretrained=True,\n",
        "        dropout_rate=0.4,\n",
        "        use_multi_label=True,  # Multiple diseases can co-exist\n",
        "        use_auxiliary_classifier=True,  # Use features from multiple stages\n",
        "    )\n",
        "\n",
        "    # Configure for fine-tuning\n",
        "    print(\"\\n🔧 Configuring for fine-tuning...\")\n",
        "    model.freeze_backbone_layers(unfreeze_last_n=2)  # Unfreeze last 2 stages\n",
        "\n",
        "    # Test with dummy fundus image\n",
        "    print(\"\\n🧪 Testing with dummy fundus image batch...\")\n",
        "    batch_size = 4\n",
        "    dummy_fundus = torch.randn(batch_size, 3, 224, 224)\n",
        "    device = next(model.parameters()).device\n",
        "    dummy_fundus = dummy_fundus.to(device)\n",
        "\n",
        "    # Forward pass\n",
        "    with torch.no_grad():\n",
        "        outputs = model(dummy_fundus)\n",
        "\n",
        "        if isinstance(outputs, dict):\n",
        "            logits = outputs['main']\n",
        "            print(f\"✓ Main logits shape: {logits.shape}\")\n",
        "            if 'auxiliary' in outputs:\n",
        "                for stage, aux_logits in outputs['auxiliary'].items():\n",
        "                    print(f\"  {stage} logits shape: {aux_logits.shape}\")\n",
        "        else:\n",
        "            logits = outputs\n",
        "            print(f\"✓ Logits shape: {logits.shape}\")\n",
        "\n",
        "        # Get probabilities\n",
        "        probs = model.predict_proba(dummy_fundus)\n",
        "        print(f\"✓ Probabilities shape: {probs.shape}\")\n",
        "\n",
        "        # Example interpretation\n",
        "        print(f\"\\n📊 Example prediction for first image:\")\n",
        "        if model.use_multi_label:\n",
        "            threshold = 0.3  # Lower threshold for medical screening\n",
        "            pred_mask = (probs[0] > threshold).cpu().numpy()\n",
        "\n",
        "            print(f\"  Threshold: {threshold}\")\n",
        "            print(f\"  Predicted diseases:\")\n",
        "            for i, (disease, pred) in enumerate(zip(systemic_diseases, pred_mask)):\n",
        "                if pred:\n",
        "                    prob = probs[0, i].item()\n",
        "                    print(f\"    • {disease}: {prob:.3f}\")\n",
        "        else:\n",
        "            pred_idx = torch.argmax(probs[0]).item()\n",
        "            pred_prob = probs[0, pred_idx].item()\n",
        "            print(f\"  Predicted: {systemic_diseases[pred_idx]} ({pred_prob:.3f})\")\n",
        "\n",
        "    # Test attention maps\n",
        "    print(\"\\n👁️ Testing attention map extraction...\")\n",
        "    attention_maps = model.get_attention_maps(dummy_fundus[:1], stage_idx=-1)\n",
        "    print(f\"  Attention maps shape: {attention_maps.shape}\")\n",
        "\n",
        "    # Save model\n",
        "    print(\"\\n💾 Saving model configuration...\")\n",
        "    model_config = {\n",
        "        'diseases': systemic_diseases,\n",
        "        'model_name': model.model_name,\n",
        "        'num_diseases': model.num_diseases,\n",
        "        'use_multi_label': model.use_multi_label,\n",
        "        'use_auxiliary_classifier': model.use_auxiliary_classifier,\n",
        "        'input_size': 224,\n",
        "        'frozen_stages': 'first 2 stages frozen',\n",
        "        'timestamp': '2024'\n",
        "    }\n",
        "\n",
        "    # Save full model\n",
        "    save_path = \"swin_systemic_disease_detector.pth\"\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'model_config': model_config,\n",
        "        'swin_config': model.config,\n",
        "    }, save_path)\n",
        "\n",
        "    print(f\"✓ Model saved to {save_path}\")\n",
        "    print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "732de69f"
      },
      "source": [
        "To install Python libraries in a Colab notebook, you can use `!pip install <package_name>`. For example, to install `numpy`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc88467e",
        "outputId": "e42ef39f-c087-443d-8974-c0f316783ec6"
      },
      "source": [
        "!pip install numpy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68036e04"
      },
      "source": [
        "You can also specify a particular version of a library:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        },
        "id": "2231d158",
        "outputId": "31e9d568-5f3a-4895-bed3-39f1d24fd4c1"
      },
      "source": [
        "!pip install pandas==1.3.5"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandas==1.3.5\n",
            "  Downloading pandas-1.3.5.tar.gz (4.7 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/4.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/4.7 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from pandas==1.3.5) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.12/dist-packages (from pandas==1.3.5) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.12/dist-packages (from pandas==1.3.5) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7.3->pandas==1.3.5) (1.17.0)\n",
            "Building wheels for collected packages: pandas\n",
            "  Building wheel for pandas (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandas: filename=pandas-1.3.5-cp312-cp312-linux_x86_64.whl size=40409652 sha256=f04a91cdad27221ce73a486b5b2208657afb3097e032879f0a1211c50016817e\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/15/7f/43571d4c48966d63f4f7a640e9345b57e23f1656d4d5b81b16\n",
            "Successfully built pandas\n",
            "Installing collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.3.5 which is incompatible.\n",
            "inequality 1.1.2 requires pandas>=2.1, but you have pandas 1.3.5 which is incompatible.\n",
            "pysal 25.7 requires pandas>=1.4, but you have pandas 1.3.5 which is incompatible.\n",
            "mizani 0.13.5 requires pandas>=2.2.0, but you have pandas 1.3.5 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 1.3.5 which is incompatible.\n",
            "cudf-cu12 25.10.0 requires pandas<2.4.0dev0,>=2.0, but you have pandas 1.3.5 which is incompatible.\n",
            "xarray 2025.11.0 requires pandas>=2.2, but you have pandas 1.3.5 which is incompatible.\n",
            "geopandas 1.1.1 requires pandas>=2.0.0, but you have pandas 1.3.5 which is incompatible.\n",
            "pointpats 2.5.2 requires pandas!=1.5.0,>=1.4, but you have pandas 1.3.5 which is incompatible.\n",
            "momepy 0.10.0 requires pandas>=2.0, but you have pandas 1.3.5 which is incompatible.\n",
            "dask-cudf-cu12 25.10.0 requires pandas<2.4.0dev0,>=2.0, but you have pandas 1.3.5 which is incompatible.\n",
            "spopt 0.7.0 requires pandas>=2.1.0, but you have pandas 1.3.5 which is incompatible.\n",
            "bigframes 2.29.1 requires pandas>=1.5.3, but you have pandas 1.3.5 which is incompatible.\n",
            "arviz 0.22.0 requires pandas>=2.1.0, but you have pandas 1.3.5 which is incompatible.\n",
            "mapclassify 2.10.0 requires pandas>=2.1, but you have pandas 1.3.5 which is incompatible.\n",
            "statsmodels 0.14.5 requires pandas!=2.1.0,>=1.4, but you have pandas 1.3.5 which is incompatible.\n",
            "libpysal 4.13.0 requires pandas>=1.4, but you have pandas 1.3.5 which is incompatible.\n",
            "db-dtypes 1.4.4 requires pandas>=1.5.3, but you have pandas 1.3.5 which is incompatible.\n",
            "esda 2.8.0 requires pandas>=2.1, but you have pandas 1.3.5 which is incompatible.\n",
            "spaghetti 1.7.6 requires pandas!=1.5.0,>=1.4, but you have pandas 1.3.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-1.3.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              },
              "id": "db63063b818840e08ec8bdcad1c024e2"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}